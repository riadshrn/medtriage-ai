import os
import chromadb
from chromadb.utils import embedding_functions
from dataclasses import dataclass
from typing import Union, List
from src.api.schemas.extraction import ExtractedPatient, ExtractedConstantes # Ton mod√®le Pydantic existant

DB_PATH = os.path.join(os.getcwd(), "data", "vector_db")
COLLECTION_NAME = "medical_knowledge"

# Initialisation Globale (pour la performance)
print(f"üîå Chargement du mod√®le d'embedding et connexion √† ChromaDB √† {DB_PATH}...")

try:
    # 1. Le mod√®le doit √™tre STRICTEMENT le m√™me que dans ingest.py
    ef = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="paraphrase-multilingual-MiniLM-L12-v2"
    )

    # 2. Connexion au client (Mode Persistant)
    client = chromadb.PersistentClient(path=DB_PATH)

    # 3. R√©cup√©ration de la collection
    collection = client.get_collection(name=COLLECTION_NAME, embedding_function=ef)
    print("‚úÖ RAG Service: Base de connaissances charg√©e avec succ√®s.")

except Exception as e:
    print(f"‚ö†Ô∏è RAG Service: Impossible de charger la base vectorielle. Erreur: {e}")
    collection = None

# Liste d√©finie c√¥t√© Code (Single Source of Truth)
REQUIRED_FOR_ML = {
    "age", "sexe", 
    "constantes.frequence_cardiaque", 
    "constantes.pression_systolique", 
    "constantes.pression_diastolique", 
    "constantes.temperature", 
    "constantes.saturation_oxygene", 
    "constantes.frequence_respiratoire"
}


# 1. On d√©finit la structure de notre "M√©moire Partag√©e"
@dataclass
class AgentState:
    patient_data: ExtractedPatient

async def search_medical_protocol(symptome: str) -> str:
    """
    Cherche dans la base de connaissances m√©dicale (RAG) les protocoles ou cas similaires.
    Args:
        symptome: Le sympt√¥me principal, la situation ou la question m√©dicale.
    Returns:
        Un texte consolid√© contenant les r√®gles et contextes trouv√©s.
    """
    if collection is None:
        return "ERREUR TECHNIQUE : La base de connaissances est inaccessible."

    try:
        # On interroge la base (On r√©cup√®re les 3 r√©sultats les plus proches)
        results = collection.query(
            query_texts=[symptome],
            n_results=3
        )
        
        # Formatage de la r√©ponse pour l'Agent
        # Chroma renvoie une liste de listes (car on peut envoyer plusieurs query_texts)
        documents = results['documents'][0]
        metadatas = results['metadatas'][0]
        
        context_text = f"--- R√âSULTATS DE LA RECHERCHE POUR : '{symptome}' ---\n"
        
        for i, doc in enumerate(documents):
            meta = metadatas[i]
            source_type = meta.get('source', 'inconnu')
            titre = meta.get('topic', 'Sans titre')
            
            context_text += f"\n[SOURCE {i+1} : {source_type} - {titre}]\n{doc}\n"
            print(context_text)
            
        return context_text

    except Exception as e:
        return f"Erreur lors de la recherche dans le protocole : {str(e)}"

async def check_completeness_for_ml(found_fields: List[str]) -> str:
    """
    V√©rifie si les donn√©es extraites sont suffisantes pour l'algorithme de pr√©diction.
    Args:
        found_fields: Liste des champs identifi√©s (ex: ['age', 'douleur', 'temperature']).
    Returns:
        Un message indiquant les variables manquantes ou un succ√®s.
    """
    # Normalisation simple pour la comparaison
    found_set = set(f.lower() for f in found_fields)
    
    # On regarde ce qui manque
    missing = []
    for req in REQUIRED_FOR_ML:
        # On g√®re le cas "constantes.temperature" vs juste "temperature"
        key_check = req.split('.')[-1] 
        if key_check not in found_set and req not in found_set:
            missing.append(req)
            
    if not missing:
        return "‚úÖ TOUTES les donn√©es requises pour le ML sont pr√©sentes."
    else:
        return f"‚ö†Ô∏è ALERTE ML - Variables manquantes pour l'algorithme : {', '.join(missing)}. Ajoute-les √† 'missing_info'."