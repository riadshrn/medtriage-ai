import os
import time
from pydantic_ai import Agent
from pydantic_ai.models.mistral import MistralModel

# Imports mis √† jour
from api.services.med_tools import search_medical_protocol, check_completeness_for_ml
from api.schemas.agent_io import AgentResponse 

class MedicalAgentService:
    def __init__(self):
        model_name = os.getenv("LLM_MODEL", "mistral-small-latest")
        if "/" in model_name: 
            model_name = model_name.split("/")[-1]

        self.model = MistralModel(model_name)
        
        self.agent = Agent(
            self.model,
            result_type=AgentResponse, # <-- L'Agent va maintenant remplir tes 3 champs
            
            system_prompt=(
                "Tu es un Copilote de R√©gulation M√©dicale."
                "Ta mission : Analyser le cas clinique et pr√©parer les donn√©es pour l'IA pr√©dictive."
                
                "FLUX DE TRAVAIL (Respecte cet ordre) :"
                "1. üß† ANALYSE : Identifie les sympt√¥mes et donn√©es pr√©sentes dans le texte."
                "2. üìö PROTOCOLE : Si un sympt√¥me t'inqui√®te, interroge 'search_medical_protocol'."
                "3. ‚úÖ VALIDATION TECHNIQUE : Appelle 'check_completeness_for_ml' avec la liste des infos que tu as trouv√©es pour savoir ce qu'il manque au mod√®le ML."
                "4. üìù R√âDACTION : G√©n√®re la r√©ponse finale."
                
                "R√àGLES DE REMPLISSAGE :"
                "- 'missing_info' : Combine les manques cliniques (li√©s au protocole) ET les manques techniques (relev√©s par l'outil de validation)."
                "- 'protocol_alert' : Remplis uniquement si le protocole m√©dical indique une urgence ou une action sp√©cifique."
            ),
            tools=[search_medical_protocol, check_completeness_for_ml] 
        )

    def _estimate_impact(self, input_tok: int, output_tok: int, latency_s: float):
        """
        Calcul Scientifique (R¬≤=1.000) bas√© sur la R√©gression Multiple.
        Formule : CO2 = a*Tokens + b*Latence + c
        """
        total_tokens = input_tok + output_tok
        
        # --- COEFFICIENTS CALIBR√âS (Mistral Small / FRA) ---
        COEFF_TOKENS  = 0.002726 # mg/token
        COEFF_LATENCY = 0.180694 # mg/seconde
        INTERCEPT     = -0.0291  # mg

        # 1. Calcul GWP (mg -> conversion kg pour stockage)
        gwp_mg = (total_tokens * COEFF_TOKENS) + (latency_s * COEFF_LATENCY) + INTERCEPT
        gwp_mg = max(0.0, gwp_mg) 
        gwp_kg = gwp_mg / 1e6

        # 2. Estimation Co√ªt ($0.1 / 1M tokens)
        cost = (total_tokens / 1_000_000) * 0.10
        
        # 3. Energie (Ratio France : 1 kWh ‚âà 0.055 kgCO2)
        energy_kwh = gwp_kg / 0.055 

        return {
            "input_tokens": input_tok,
            "output_tokens": output_tok,
            "total_tokens": total_tokens,
            "latency_s": latency_s,
            "cost_usd": cost,
            "gwp_kgco2": gwp_kg,
            "energy_kwh": energy_kwh
        }
    
    def _check_ml_constraints(self, data: dict, current_missing: list) -> list:
        """
        V√©rifie si les champs obligatoires pour le ML sont pr√©sents.
        Si non, les ajoute √† la liste des infos manquantes.
        """
        missing_technical = []
        constantes = data.get('constantes', {})

        for field_path, human_name in self.ML_REQUIRED_FIELDS.items():
            val = None
            
            # R√©cup√©ration de la valeur (support des niveaux imbriqu√©s comme 'constantes.temp')
            if "." in field_path:
                parent, child = field_path.split(".")
                val = constantes.get(child)
            else:
                val = data.get(field_path)

            # Si la valeur est None (ou vide), c'est un manque technique
            if val is None:
                # On v√©rifie si l'agent ne l'a pas d√©j√† demand√© (pour √©viter les doublons)
                # On fait une v√©rif simple sur le texte
                already_asked = any(human_name.lower() in q.lower() for q in current_missing)
                if not already_asked:
                    missing_technical.append(f"{human_name} (Requis pour l'IA Pr√©dictive)")
        
        # On fusionne : D'abord les manques cliniques (Agent), puis les manques techniques (Python)
        return current_missing + missing_technical

    async def analyze_with_reasoning(self, full_text: str):
        try:
            start_time = time.time()
            
            # L'Agent g√©n√®re l'objet AgentResponse
            result = await self.agent.run(f"Analyse ce patient :\n{full_text}")
            
            end_time = time.time()
            latency_s = end_time - start_time

            # R√©cup√©ration Logs Outils
            steps = []
            for msg in result.new_messages():
                if hasattr(msg, 'parts'):
                    for part in msg.parts:
                        if hasattr(part, 'tool_name'):
                            args = getattr(part, 'args', {})
                            steps.append(f"üõ†Ô∏è **Recherche RAG** : `{part.tool_name}`") # Affichage simplifi√©
                        elif hasattr(part, 'content') and hasattr(msg, 'kind') and msg.kind == 'tool-return':
                             steps.append(f"‚úÖ **R√©sultat** : {part.content[:80]}...")

            # M√©triques
            usage = result.usage()
            impacts = self._estimate_impact(usage.request_tokens, usage.response_tokens, latency_s)

            # Extraction
            final_obj = result.data 

            return {
                # On √©clate la r√©ponse pour le frontend
                "missing_info": final_obj.missing_info,
                "protocol_alert": final_obj.protocol_alert,
                "extracted_data": final_obj.data.model_dump(),
                
                "reasoning_steps": steps,
                "metrics": impacts
            }
            
        except Exception as e:
            print(f"‚ùå CRASH AGENT: {e}")
            return {
                "extracted_data": None,
                "missing_info": [],
                "protocol_alert": "Erreur syst√®me",
                "reasoning_steps": [f"‚ùå Erreur : {str(e)}"],
                "metrics": None
            }

# Singleton
_agent_instance = None
def get_agent_service():
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = MedicalAgentService()
    return _agent_instance