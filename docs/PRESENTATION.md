# üèóÔ∏è Architecture Technique - Projet MedTriage AI

Ce document d√©taille la structure du code et la responsabilit√© de chaque module. L'architecture suit une s√©paration stricte entre la couche de pr√©sentation (Frontend), la couche de contr√¥le (Routes) et la couche m√©tier (Services).

## 1. Infrastructure & Orchestration

* **`docker-compose.yml`** : Orchestration des conteneurs.
    * D√©finit deux services : `api` (Backend) et `ui` (Frontend).
    * G√®re le montage des volumes (`./src:/app/src`) pour le *hot-reloading* en d√©veloppement.
    * G√®re le r√©seau interne pour la communication `ui` -> `api`.
* **`.env`** : Configuration des variables d'environnement (Cl√©s API Mistral/OpenAI, configuration EcoLogits, URLs).

---

## 2. Backend (`src/api`) - FastAPI

Le backend expose une API RESTful typ√©e.

### üìÇ `routes/` (Contr√¥leurs)
Responsable de la r√©ception des requ√™tes HTTP, de la validation des entr√©es et de la r√©ponse format√©e. Ne contient **aucune logique m√©tier complexe**.

* **`conversation.py`** :
    * `POST /upload` : G√®re le parsing des fichiers CSV/TXT vers un format JSON standardis√©.
    * `POST /process` : Point d'entr√©e principal. Orchestre l'appel s√©quentiel aux services (Extraction -> Triage) et retourne un objet `SimulationResult` complet.

### üìÇ `services/` (Logique M√©tier)
C≈ìur fonctionnel de l'application. Chaque service est ind√©pendant.

* **`extraction_service.py`** : **Interface LLM (Generative AI)**.
    * Utilise `litellm` pour communiquer avec les mod√®les (Mistral, GPT, Ollama).
    * Int√®gre `EcoLogits` pour monitorer l'empreinte carbone et √©nerg√©tique de chaque appel en temps r√©el.
    * Transforme le texte brut en donn√©es structur√©es via Pydantic (Extraction d'entit√©s m√©dicales).
* **`triage_service.py`** : **Moteur de d√©cision (Predictive AI)**.
    * Impl√©mente l'algorithme "French Emergency Nurses Classification" (r√®gles m√©tiers).
    * Charge le mod√®le Machine Learning (XGBoost) via `models/trained/`.
    * Combine les r√®gles et la pr√©diction ML pour fournir un score de gravit√© et de confiance.

### üìÇ `schemas/` (Data Transfer Objects)
D√©finitions Pydantic pour la validation stricte des donn√©es (Typage fort).

* **`extraction.py`** : Structure attendue en sortie du LLM (Patient, Constantes, Ant√©c√©dents).
* **`triage.py`** : Structure d'entr√©e pour le moteur de triage (Normalisation des donn√©es).
* **`monitoring.py`** : Structure des m√©triques FinOps/GreenOps (Co√ªts, Latence, CO2).

---

## 3. Frontend (`src/interface`) - Streamlit

Interface utilisateur "Stateless" qui consomme l'API.

* **`app.py`** : Point d'entr√©e, gestion de la navigation et configuration globale de la page.
* **`state.py`** : Gestion de la persistance de session (`st.session_state`). Permet de conserver les donn√©es (chat, r√©sultats d'analyse) lors de la navigation entre les pages.
* **`pages/`** :
    * **`0_Accueil.py`** : Upload de fichier, affichage de la conversation (Chat UI), et d√©clenchement de l'analyse.
    * **`2_Dashboard.py`** : Visualisation des KPIs techniques (Latence, Tokens, Empreinte Carbone) bas√©s sur la derni√®re requ√™te.

---

## üîÑ Flux de Donn√©es (Pipeline `/process`)

1.  **Input** : Le JSON de la conversation est re√ßu par la Route.
2.  **Extraction** : Le `ExtractionService` appelle le LLM.
    * *Input* : Transcript brut.
    * *Output* : JSON structur√© (Age, Douleur, Constantes) + M√©triques EcoLogits.
3.  **Triage** : Le `TriageService` re√ßoit le JSON structur√©.
    * Il applique les r√®gles m√©tiers.
    * Il encode les features et interroge le mod√®le XGBoost.
4.  **Output** : L'API renvoie un objet unique contenant :
    * Les donn√©es extraites.
    * Le r√©sultat du triage (Gravit√©, Orientation).
    * Les m√©triques de performance et d'√©cologie.